from collections import deque
import heapq
import random
import math
import time
from .utils import generate_random_state, manhattan_distance
from heapq import heappop, heappush
from .utils import is_solvable
import pygame

# HÃ m giáº£i thuáº­t BFS (Breadth-First Search): tÃ¬m kiáº¿m theo chiá»u rá»™ng, má»Ÿ rá»™ng táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i cÃ¹ng má»™t má»©c Ä‘á»™ trÆ°á»›c khi chuyá»ƒn sang má»©c Ä‘á»™ tiáº¿p theo
def bfs_solve(start_state):
    return generic_solve(start_state, queue=deque([(start_state, [])]), pop_method='popleft')

# HÃ m giáº£i thuáº­t DFS (Depth-First Search): tÃ¬m kiáº¿m theo chiá»u sÃ¢u, má»Ÿ rá»™ng cÃ¡c tráº¡ng thÃ¡i theo chiá»u sÃ¢u trÆ°á»›c khi quay láº¡i
def dfs_solve(start_state, max_depth=100):
    stack = [(start_state, [], 0)]  # ThÃªm má»™t giÃ¡ trá»‹ depth vÃ o má»—i pháº§n tá»­
    visited = set()
    visited.add(tuple(start_state))

    while stack:
        state, path, depth = stack.pop()

        if state == list(range(1, 9)) + [0]:
            return path

        if depth >= max_depth:  # Náº¿u chiá»u sÃ¢u vÆ°á»£t quÃ¡ max_depth thÃ¬ tiáº¿p tá»¥c
            continue

        zero_idx = state.index(0)  
        moves = [-3, 3, -1, 1]  

        # Generate next states
        for move in moves:
            new_idx = zero_idx + move
            if 0 <= new_idx < 9 and (
                (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or  
                (move in [-3, 3]) 
            ):
                new_state = state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                if tuple(new_state) not in visited:
                    visited.add(tuple(new_state))
                    stack.append((new_state, path + [(zero_idx, new_idx)], depth + 1))  # Cáº­p nháº­t chiá»u sÃ¢u

    return None


# HÃ m giáº£i thuáº­t Generic Solve: hÃ m tá»•ng quÃ¡t cho cÃ¡c thuáº­t toÃ¡n tÃ¬m kiáº¿m khÃ¡c nhau
def generic_solve(start_state, queue, pop_method='pop', is_priority=False):
    goal_state = list(range(1, 9)) + [0]
    visited = set()
    visited.add(tuple(start_state))

    while queue:
        if is_priority:
            _, g, state, path = heapq.heappop(queue)
        elif pop_method == 'heappop':
            _, state, path = heapq.heappop(queue)
        else:
            if pop_method == 'pop':
                state, path = queue.pop()
            else:
                state, path = queue.popleft()

        if state == goal_state:
            return path

        zero_idx = state.index(0)
        moves = [-3, 3, -1, 1]

        for move in moves:
            new_idx = zero_idx + move
            if 0 <= new_idx < 9 and (
                (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or
                (move in [-3, 3])
            ):
                new_state = state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                if tuple(new_state) not in visited:
                    visited.add(tuple(new_state))

                    if is_priority:
                        h = manhattan_distance(new_state)
                        new_g = g + 1
                        f = new_g + h
                        heapq.heappush(queue, (f, new_g, new_state, path + [(zero_idx, new_idx)]))
                    elif pop_method == 'heappop':
                        heapq.heappush(queue, (manhattan_distance(new_state), new_state, path + [(zero_idx, new_idx)]))
                    else:
                        queue.append((new_state, path + [(zero_idx, new_idx)]))

    return None

# HÃ m giáº£i thuáº­t UCS (Uniform Cost Search): má»Ÿ rá»™ng cÃ¡c tráº¡ng thÃ¡i theo thá»© tá»± tá»•ng chi phÃ­ nhá» nháº¥t tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i hiá»‡n táº¡i.
def ucs_solve(start_state):
    # Sá»­ dá»¥ng generic_solve vá»›i hÃ ng Ä‘á»£i Æ°u tiÃªn theo chi phÃ­
    goal_state = list(range(1, 9)) + [0]
    visited = set()
    visited.add(tuple(start_state))  # ThÃªm tráº¡ng thÃ¡i ban Ä‘áº§u vÃ o táº­p Ä‘Ã£ duyá»‡t
    queue = [(0, start_state, [])]  # (chi phÃ­, tráº¡ng thÃ¡i, Ä‘Æ°á»ng Ä‘i)
    
    while queue:
        cost, state, path = heapq.heappop(queue)
        
        if state == goal_state:
            return path
        
        zero_idx = state.index(0)
        moves = [-3, 3, -1, 1]
        
        for move in moves:
            new_idx = zero_idx + move
            if 0 <= new_idx < 9 and ((move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])):
                new_state = state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
                
                if tuple(new_state) not in visited:
                    visited.add(tuple(new_state))
                    # Trong UCS, chi phÃ­ lÃ  sá»‘ bÆ°á»›c Ä‘Ã£ Ä‘i
                    heapq.heappush(queue, (cost + 1, new_state, path + [(zero_idx, new_idx)]))
    
    return None

# HÃ m giáº£i thuáº­t Greedy: má»Ÿ rá»™ng cÃ¡c tráº¡ng thÃ¡i theo thá»© tá»± Æ°u tiÃªn dá»±a trÃªn heuristic (á»Ÿ Ä‘Ã¢y lÃ  khoáº£ng cÃ¡ch Manhattan)
def greedy_solve(start_state):
    return generic_solve(start_state, queue=[(manhattan_distance(start_state), start_state, [])], pop_method='heappop')

# HÃ m giáº£i thuáº­t tÃ¬m kiáº¿m sÃ¢u dáº§n láº·p IDDFS (Iterative Deepening Depth-First Search): tÃ¬m kiáº¿m theo chiá»u sÃ¢u vá»›i giá»›i háº¡n Ä‘á»™ sÃ¢u tÄƒng dáº§n
def iddfs_solve(start_state):
    goal_state = list(range(1, 9)) + [0] # Tráº¡ng thÃ¡i Ä‘Ã­ch (1,2,3,4,5,6,7,8,0)

    # HÃ m dls (Depth-Limited Search): tÃ¬m kiáº¿m theo chiá»u sÃ¢u vá»›i giá»›i háº¡n Ä‘á»™ sÃ¢u
    def dls(state, path, depth_limit, visited):
        if state == goal_state:
            return path
        if len(path) >= depth_limit:
            return None

        zero_idx = state.index(0)
        moves = [-3, 3, -1, 1]  # LÃªn, Xuá»‘ng, TrÃ¡i, Pháº£i
        next_states = []

        for move in moves:
            new_idx = zero_idx + move
            if 0 <= new_idx < 9 and (
                (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or
                (move in [-3, 3])
            ):
                new_state = state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                if tuple(new_state) not in visited:
                    next_states.append((new_state, path + [(zero_idx, new_idx)]))

        # Æ¯u tiÃªn tráº¡ng thÃ¡i gáº§n lá»i giáº£i hÆ¡n báº±ng Manhattan Distance Ä‘á»ƒ giáº£m sá»‘ bÆ°á»›c láº·p khÃ´ng cáº§n thiáº¿t
        next_states.sort(key=lambda x: manhattan_distance(x[0]))
        # Duyá»‡t qua tá»«ng tráº¡ng thÃ¡i tiáº¿p theo
        for new_state, new_path in next_states:
            visited.add(tuple(new_state)) # ÄÃ¡nh dáº¥u tráº¡ng thÃ¡i Ä‘Ã£ duyá»‡t
            result = dls(new_state, new_path, depth_limit, visited) # Gá»i Ä‘á»‡ quy vá»›i tráº¡ng thÃ¡i má»›i
            if result is not None:
                return result
            visited.remove(tuple(new_state))  # Bá» Ä‘Ã¡nh dáº¥u náº¿u khÃ´ng tÃ¬m tháº¥y lá»i giáº£i

        return None

    # DÃ¹ng Iterative Deepening vá»›i nhiá»u Ä‘á»™ sÃ¢u khÃ¡c nhau
    for depth_limit in range(5, 50, 5):  # TÄƒng dáº§n giá»›i háº¡n Ä‘á»™ sÃ¢u
        visited = set([tuple(start_state)])
        solution = dls(start_state, [], depth_limit, visited)
        if solution is not None:
            return solution  # Náº¿u tÃ¬m tháº¥y lá»i giáº£i, tráº£ vá» ngay

    return None  # KhÃ´ng tÃ¬m tháº¥y lá»i giáº£i

# HÃ m giáº£i thuáº­t A* (A Star Search)
def astar_solve(start_state):
    return generic_solve(start_state, queue=[(manhattan_distance(start_state), 0, start_state, [])], pop_method='heappop', is_priority=True)

# HÃ m giáº£i thuáº­t IDA* (Iterative Deepening A* Search)
def idastar_solve(start_state):
    goal_state = list(range(1, 9)) + [0]  # Tráº¡ng thÃ¡i Ä‘Ã­ch

    def search(state, path, g, threshold, visited):
        f = g + manhattan_distance(state)  # f(n) = g(n) + h(n)
        # Náº¿u f vÆ°á»£t ngÆ°á»¡ng, tráº£ vá» ngÆ°á»¡ng má»›i
        if f > threshold:
            return f, None 
        if state == goal_state:
            return f, path  # TÃ¬m tháº¥y lá»i giáº£i

        min_threshold = float('inf') # NgÆ°á»¡ng nhá» nháº¥t
        zero_idx = state.index(0)
        moves = [-3, 3, -1, 1]

        for move in moves:
            new_idx = zero_idx + move
            if 0 <= new_idx < 9 and ((move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])):
                new_state = state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                if tuple(new_state) not in visited:
                    visited.add(tuple(new_state))
                    new_threshold, result = search(new_state, path + [(zero_idx, new_idx)], g + 1, threshold, visited)
                    visited.remove(tuple(new_state))
                    
                    if result is not None:
                        return new_threshold, result  # Náº¿u tÃ¬m tháº¥y lá»i giáº£i, tráº£ vá» ngay
                    min_threshold = min(min_threshold, new_threshold)

        return min_threshold, None  # Tráº£ vá» giÃ¡ trá»‹ ngÆ°á»¡ng má»›i
     
    # Báº¯t Ä‘áº§u vá»›i ngÆ°á»¡ng ban Ä‘áº§u lÃ  heuristic cá»§a tráº¡ng thÃ¡i ban Ä‘áº§u
    threshold = manhattan_distance(start_state)  # Báº¯t Ä‘áº§u vá»›i h(n)
    
    while True:
        visited = set([tuple(start_state)])
        threshold, solution = search(start_state, [], 0, threshold, visited) # Láº·p láº¡i tÃ¬m kiáº¿m, tÄƒng dáº§n ngÆ°á»¡ng
        if solution is not None:
            return solution  # Náº¿u tÃ¬m tháº¥y lá»i giáº£i, tráº£ vá»
        if threshold == float('inf'):
            return None  # KhÃ´ng tÃ¬m tháº¥y lá»i giáº£i

# HÃ m giáº£i thuáº­t Hill Climbing: tÃ¬m kiáº¿m theo chiá»u cao, má»Ÿ rá»™ng tráº¡ng thÃ¡i tá»‘t nháº¥t táº¡i má»—i bÆ°á»›c
def hill_climbing_solve(start_state):
    goal_state = list(range(1, 9)) + [0]
    current_state = start_state[:]
    path = []
    
    while current_state != goal_state:
        # TÃ¬m vá»‹ trÃ­ Ã´ trá»‘ng
        zero_idx = current_state.index(0)
        
        # Khá»Ÿi táº¡o giÃ¡ trá»‹ heuristic tá»‘t nháº¥t
        best_heuristic = manhattan_distance(current_state) # TÃ­nh toÃ¡n heuristic cho tráº¡ng thÃ¡i hiá»‡n táº¡i
        best_move = None # TÃ¬m bÆ°á»›c Ä‘i tá»‘t nháº¥t
        
        # CÃ¡c hÆ°á»›ng di chuyá»ƒn
        moves = [-3, 3, -1, 1]
        
        for move in moves:
            new_idx = zero_idx + move
            # Kiá»ƒm tra di chuyá»ƒn há»£p lá»‡
            if 0 <= new_idx < 9 and ((move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])):
                # Táº¡o tráº¡ng thÃ¡i má»›i
                new_state = current_state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
                
                # TÃ­nh heuristic cá»§a tráº¡ng thÃ¡i má»›i
                new_heuristic = manhattan_distance(new_state)
                
                # Chá»n tráº¡ng thÃ¡i cÃ³ heuristic tá»‘t hÆ¡n (nhá» hÆ¡n)
                if new_heuristic < best_heuristic:
                    best_heuristic = new_heuristic
                    best_move = (zero_idx, new_idx)
        
        # Náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c bÆ°á»›c Ä‘i tá»‘t hÆ¡n, káº¿t thÃºc
        if best_move is None:
            return None
        
        # Thá»±c hiá»‡n di chuyá»ƒn   
        zero_idx, new_idx = best_move
        current_state[zero_idx], current_state[new_idx] = current_state[new_idx], current_state[zero_idx]
        path.append(best_move)
    
    return path

# HÃ m giáº£i thuáº­t Steepest Ascent Hill Climbing: tÃ¬m kiáº¿m theo chiá»u cao vá»›i bÆ°á»›c Ä‘i tá»‘t nháº¥t táº¡i má»—i bÆ°á»›c
def steepest_ascent_hill_climbing_solve(start_state):
    goal_state = list(range(1, 9)) + [0]
    current_state = start_state[:]
    path = []
    
    while current_state != goal_state:
        # TÃ¬m vá»‹ trÃ­ Ã´ trá»‘ng
        zero_idx = current_state.index(0)
        
        # Khá»Ÿi táº¡o giÃ¡ trá»‹ heuristic tá»‘t nháº¥t
        best_heuristic = manhattan_distance(current_state)
        best_moves = []
        
        # CÃ¡c hÆ°á»›ng di chuyá»ƒn
        moves = [-3, 3, -1, 1]
        
        for move in moves:
            new_idx = zero_idx + move
            # Kiá»ƒm tra di chuyá»ƒn há»£p lá»‡
            if 0 <= new_idx < 9 and ((move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])):
                # Táº¡o tráº¡ng thÃ¡i má»›i
                new_state = current_state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
                
                # TÃ­nh heuristic cá»§a tráº¡ng thÃ¡i má»›i
                new_heuristic = manhattan_distance(new_state)
                
                # LÆ°u táº¥t cáº£ cÃ¡c bÆ°á»›c Ä‘i cÃ³ heuristic tá»‘t nháº¥t
                if new_heuristic < best_heuristic:
                    best_heuristic = new_heuristic
                    best_moves = [(zero_idx, new_idx)]
                elif new_heuristic == best_heuristic:
                    best_moves.append((zero_idx, new_idx))
        
        # Náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c bÆ°á»›c Ä‘i tá»‘t hÆ¡n, káº¿t thÃºc
        if not best_moves:
            return None
        
        # Chá»n ngáº«u nhiÃªn má»™t trong cÃ¡c bÆ°á»›c Ä‘i tá»‘t nháº¥t náº¿u cÃ³ nhiá»u hÆ¡n má»™t
        zero_idx, new_idx = best_moves[0] if len(best_moves) == 1 else best_moves[len(best_moves) // 2]  
        
        # Thá»±c hiá»‡n di chuyá»ƒn   
        current_state[zero_idx], current_state[new_idx] = current_state[new_idx], current_state[zero_idx]
        path.append((zero_idx, new_idx))
    
    return path

# HÃ m giáº£i thuáº­t Hill Climbing vá»›i ngáº«u nhiÃªn
def stochastic_hill_climbing_solve(start_state):
    goal_state = list(range(1, 9)) + [0]
    current_state = start_state[:]
    path = []

    while current_state != goal_state:
        # TÃ¬m vá»‹ trÃ­ Ã´ trá»‘ng
        zero_idx = current_state.index(0)

        # Táº¡o danh sÃ¡ch cÃ¡c tráº¡ng thÃ¡i lÃ¢n cáº­n
        neighbors = []
        moves = [-3, 3, -1, 1]  # LÃªn, Xuá»‘ng, TrÃ¡i, Pháº£i

        for move in moves:
            new_idx = zero_idx + move
            # Kiá»ƒm tra di chuyá»ƒn há»£p lá»‡
            if 0 <= new_idx < 9 and ((move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])):
                # Táº¡o tráº¡ng thÃ¡i má»›i
                new_state = current_state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
                neighbors.append((new_state, (zero_idx, new_idx)))

        # Lá»c cÃ¡c tráº¡ng thÃ¡i lÃ¢n cáº­n tá»‘t hÆ¡n
        better_neighbors = [
            (state, move) for state, move in neighbors if manhattan_distance(state) < manhattan_distance(current_state)
        ]

        # Náº¿u khÃ´ng cÃ³ tráº¡ng thÃ¡i tá»‘t hÆ¡n, dá»«ng láº¡i
        if not better_neighbors:
            return None

        # Chá»n ngáº«u nhiÃªn má»™t tráº¡ng thÃ¡i tá»‘t hÆ¡n
        next_state, move = random.choice(better_neighbors)

        # Cáº­p nháº­t tráº¡ng thÃ¡i hiá»‡n táº¡i
        current_state = next_state
        path.append(move)

    return path

# HÃ m giáº£i thuáº­t Simulated Annealing
def simulated_annealing_solve(start_state):
    state = start_state[:]
    path = []
    goal = list(range(1, 9)) + [0]
    T = 150.0 # Nhiá»‡t Ä‘á»™ ban Ä‘áº§u
    alpha = 0.99 # Há»‡ sá»‘ lÃ m mÃ¡t
    min_temp = 0.1 # Nhiá»‡t Ä‘á»™ tá»‘i thiá»ƒu

    while True:
        if state == goal:
            return path

        zero_idx = state.index(0)
        moves = [-3, 3, -1, 1]
        best_h = manhattan_distance(state)
        best_move = None
        best_state = None

        neighbors = []

        for move in moves:
            new_idx = zero_idx + move
            if 0 <= new_idx < 9 and (
                (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])
            ):
                temp = state[:]
                temp[zero_idx], temp[new_idx] = temp[new_idx], temp[zero_idx]
                h = manhattan_distance(temp)
                neighbors.append((temp, (zero_idx, new_idx), h))

                if h < best_h:
                    best_h = h
                    best_move = move
                    best_state = temp

        if best_move:
            # CÃ³ hÆ°á»›ng tá»‘t hÆ¡n â†’ Ä‘i theo HC
            state = best_state
            path.append((zero_idx, zero_idx + best_move))
        else:
            # KhÃ´ng cÃ³ hÆ°á»›ng Ä‘i tá»‘t hÆ¡n â†’ dÃ¹ng SA Ä‘á»ƒ thoÃ¡t
            if not neighbors:
                break
            next_state, move, h = random.choice(neighbors)
            delta_e = manhattan_distance(state) - h # TÃ­nh toÃ¡n Ä‘á»™ thay Ä‘á»•i heuristic
            if delta_e > 0 or random.random() < math.exp(delta_e / T): # XÃ¡c suáº¥t cháº¥p nháº­n tráº¡ng thÃ¡i xáº¥u hÆ¡n
                state = next_state
                path.append(move)

            T *= alpha # Giáº£m nhiá»‡t Ä‘á»™ dáº§n theo thá»i gia/n
            if T < min_temp:
                break

    return path if state == goal else None

# HÃ m giáº£i thuáº­t Beam Search
def beam_search_solve(start_state, beam_width=2):
    goal_state = list(range(1, 9)) + [0]
    queue = [(manhattan_distance(start_state), start_state, [])]
    visited = set()

    while queue:
        # Giá»¯ láº¡i beam_width tráº¡ng thÃ¡i tá»‘t nháº¥t
        next_level = []

        for _, state, path in queue: #_ lÃ  giÃ¡ trá»‹ heuristic cáº§n dÃ¹ng Ä‘áº¿n
            if state == goal_state:
                return path

            visited.add(tuple(state))
            zero_idx = state.index(0)
            moves = [-3, 3, -1, 1]

            for move in moves:
                new_idx = zero_idx + move
                if 0 <= new_idx < 9 and (
                    (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or (move in [-3, 3])
                ):
                    new_state = state[:]
                    new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                    if tuple(new_state) not in visited:
                        new_path = path + [(zero_idx, new_idx)]
                        h = manhattan_distance(new_state)
                        heappush(next_level, (h, new_state, new_path))

        # Chá»n beam_width tráº¡ng thÃ¡i tá»‘t nháº¥t Ä‘á»ƒ tiáº¿p tá»¥c
        queue = [heappop(next_level) for _ in range(min(beam_width, len(next_level)))]

    return None  # KhÃ´ng tÃ¬m tháº¥y lá»i giáº£i

def and_or_search(max_depth=20):
    """
    AND-OR Search: Má»™t thuáº­t toÃ¡n tÃ¬m kiáº¿m cho mÃ´i trÆ°á»ng phá»©c táº¡p trong 8-puzzle.
    Thuáº­t toÃ¡n sáº½ táº¡o má»™t káº¿ hoáº¡ch cÃ³ thá»ƒ giáº£i quyáº¿t má»i kháº£ nÄƒng xáº£y ra trong mÃ´i trÆ°á»ng.
    """
    import random
    import sys
    from .utils import is_solvable, manhattan_distance
    
    # TÄƒng giá»›i háº¡n Ä‘á»‡ quy Ä‘á»ƒ trÃ¡nh lá»—i stack overflow
    sys.setrecursionlimit(10000)

    # Tráº¡ng thÃ¡i Ä‘Ã­ch
    goal_state = list(range(1, 9)) + [0]
    
    # Táº¡o má»™t tráº¡ng thÃ¡i ban Ä‘áº§u ngáº«u nhiÃªn cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c
    while True:
        start_state = list(random.sample(range(9), 9))
        if is_solvable(start_state) and start_state != goal_state:
            break
    
    # LÆ°u táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i Ä‘Ã£ thÄƒm Ä‘á»ƒ trÃ¡nh láº·p vÃ´ háº¡n
    visited = set()
    visited.add(tuple(start_state))
    
    # LÆ°u Ä‘Æ°á»ng Ä‘i Ä‘á»ƒ hiá»ƒn thá»‹
    solution_path = [start_state]
    best_path = None
    best_path_length = float('inf')
    
    def get_valid_moves(state):
        """TÃ¬m cÃ¡c nÆ°á»›c Ä‘i há»£p lá»‡ tá»« tráº¡ng thÃ¡i hiá»‡n táº¡i"""
        zero_idx = state.index(0)
        valid_moves = []
        
        # Kiá»ƒm tra 4 hÆ°á»›ng di chuyá»ƒn: lÃªn, xuá»‘ng, trÃ¡i, pháº£i
        if zero_idx >= 3:  # CÃ³ thá»ƒ Ä‘i lÃªn
            valid_moves.append((zero_idx, zero_idx - 3))
        if zero_idx < 6:  # CÃ³ thá»ƒ Ä‘i xuá»‘ng
            valid_moves.append((zero_idx, zero_idx + 3))
        if zero_idx % 3 > 0:  # CÃ³ thá»ƒ Ä‘i trÃ¡i
            valid_moves.append((zero_idx, zero_idx - 1))
        if zero_idx % 3 < 2:  # CÃ³ thá»ƒ Ä‘i pháº£i
            valid_moves.append((zero_idx, zero_idx + 1))
            
        return valid_moves
    
    def apply_move(state, move):
        """Ãp dá»¥ng nÆ°á»›c Ä‘i vÃ  tráº£ vá» tráº¡ng thÃ¡i má»›i"""
        zero_idx, swap_idx = move
        new_state = state.copy()
        new_state[zero_idx], new_state[swap_idx] = new_state[swap_idx], new_state[zero_idx]
        return new_state
    
    def dfs_with_limit(state, depth, path):
        """TÃ¬m kiáº¿m theo chiá»u sÃ¢u vá»›i giá»›i háº¡n Ä‘á»™ sÃ¢u"""
        nonlocal best_path, best_path_length
        
        # Náº¿u Ä‘áº¡t tráº¡ng thÃ¡i Ä‘Ã­ch
        if state == goal_state:
            if len(path) < best_path_length:
                best_path = path.copy()
                best_path_length = len(path)
            return True
        
        # Náº¿u vÆ°á»£t quÃ¡ Ä‘á»™ sÃ¢u tá»‘i Ä‘a
        if depth >= max_depth:
            return False
        
        # Láº¥y cÃ¡c nÆ°á»›c Ä‘i há»£p lá»‡ vÃ  sáº¯p xáº¿p theo heuristic (tá»‘t nháº¥t trÆ°á»›c)
        valid_moves = get_valid_moves(state)
        
        # Thá»­ tá»«ng nÆ°á»›c Ä‘i
        for move in valid_moves:
            new_state = apply_move(state, move)
            tuple_state = tuple(new_state)
            
            # Náº¿u tráº¡ng thÃ¡i má»›i chÆ°a thÄƒm
            if tuple_state not in visited:
                visited.add(tuple_state)
                
                # ThÃªm vÃ o Ä‘Æ°á»ng Ä‘i
                path.append(move)
                solution_path.append(new_state)
                
                # Tiáº¿p tá»¥c tÃ¬m kiáº¿m tá»« tráº¡ng thÃ¡i má»›i
                if dfs_with_limit(new_state, depth + 1, path):
                    return True
                
                # Quay lui náº¿u khÃ´ng tÃ¬m tháº¥y Ä‘Æ°á»ng Ä‘i
                path.pop()
                solution_path.pop()
        
        return False
    
    # Báº¯t Ä‘áº§u tÃ¬m kiáº¿m vá»›i chiá»u sÃ¢u tÄƒng dáº§n Ä‘á»ƒ Ä‘áº£m báº£o tÃ¬m Ä‘Æ°á»£c Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t
    found = False
    for limit in range(5, max_depth + 5, 5):
        # Reset Ä‘á»ƒ thá»­ vá»›i Ä‘á»™ sÃ¢u má»›i
        visited = set()
        visited.add(tuple(start_state))
        solution_path = [start_state]
        
        # Thá»­ tÃ¬m kiáº¿m vá»›i giá»›i háº¡n má»›i
        if dfs_with_limit(start_state, 0, []):
            found = True
            print(f"TÃ¬m tháº¥y Ä‘Æ°á»ng Ä‘i vá»›i Ä‘á»™ sÃ¢u {limit}")
            break
    
    if found and best_path:
        return {
            "start": start_state,
            "path": solution_path,
            "moves": best_path
        }
    else:
        return {
            "start": start_state,
            "path": [start_state],
            "moves": None
        }
    

from itertools import permutations
from collections import deque

def no_observation_search(start_state=None):
    goal_state = tuple([1, 2, 3, 4, 5, 6, 7, 8, 0])
    print("ğŸ“¥ Báº¯t Ä‘áº§u no_observation_search()")

    # --- Kiá»ƒm tra solvability ---
    def is_solvable(state):
        inv = 0
        for i in range(8):
            for j in range(i+1, 9):
                if state[i] and state[j] and state[i] > state[j]:
                    inv += 1
        return inv % 2 == 0

    # --- 1) Táº¡o belief ban Ä‘áº§u ---
    if start_state:
        belief0 = {tuple(start_state)}
        print(f"ğŸ” Tráº¡ng thÃ¡i Ä‘áº§u vÃ o: {start_state}")

    else:
        belief0 = set(filter(is_solvable, permutations(range(9))))
        print(f"ğŸ” Khá»Ÿi táº¡o belief vá»›i {len(belief0)} tráº¡ng thÃ¡i cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c")


    queue = deque([(belief0, [])])
    visited = set()
    expansions = 0

    moves = {
        'UP':    (-1,  0),
        'DOWN':  ( 1,  0),
        'LEFT':  ( 0, -1),
        'RIGHT': ( 0,  1)
    }

    while queue:
        belief, path = queue.popleft()
        key = frozenset(belief)
        if key in visited:
            continue
        visited.add(key)
        expansions += 1

        if all(state == goal_state for state in belief):
            print("âœ… TÃ¬m tháº¥y lá»i giáº£i!")
            print(f"ğŸªœ HÃ nh Ä‘á»™ng: {path}")
            return path

        for action, (dr, dc) in moves.items():
            new_belief = set()
            ok = True
            for st in belief:
                zero = st.index(0)
                r, c = divmod(zero, 3)
                nr, nc = r+dr, c+dc
                if 0 <= nr < 3 and 0 <= nc < 3:
                    idx2 = nr*3 + nc
                    lst  = list(st)
                    lst[zero], lst[idx2] = lst[idx2], lst[zero]
                    new_belief.add(tuple(lst))
                else:
                    ok = False
                    break
            if ok and new_belief:
                queue.append((new_belief, path + [(zero, idx2)]))

    return None


# HÃ m giáº£i thuáº­t Partial Observable Search (Belief State Search): tÃ¬m kiáº¿m vá»›i tráº¡ng thÃ¡i "quan sÃ¡t Ä‘Æ°á»£c" má»™t sá»‘ Ã´ trÃªn báº£ng (1,2,3)
def partial_observable_search(start_state):
    from collections import deque
    goal_state = list(range(1, 9)) + [0]
    observed_indices = [0, 1, 2]  # CÃ¡c Ã´ 0,1,2 Ä‘Ã£ biáº¿t cháº¯c

    # HÃ m kiá»ƒm tra tráº¡ng thÃ¡i cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c hay khÃ´ng - sá»‘ nghá»‹ch thá»ƒ lÃ  cháºµn thÃ¬ cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c vÃ  ngÆ°á»£c láº¡i
    def is_solvable(state):
        inversions = 0
        for i in range(len(state)):
            if state[i] == 0:
                continue
            for j in range(i + 1, len(state)):
                if state[j] != 0 and state[i] > state[j]:
                    inversions += 1
        return inversions % 2 == 0

    if not is_solvable(start_state):
        return None

    visited = set() # Táº­p há»£p cÃ¡c tráº¡ng thÃ¡i Ä‘Ã£ duyá»‡t Ä‘á»ƒ trÃ¡nh láº·p láº¡i
    queue = deque([(start_state, [])]) # HÃ ng Ä‘á»£i lÆ°u trá»¯ cÃ¡c tráº¡ng thÃ¡i cáº§n duyá»‡t

    while queue:
        current_state, path = queue.popleft() # Láº¥y tráº¡ng thÃ¡i Ä‘áº§u tiÃªn trong hÃ ng Ä‘á»£i

        # Kiá»ƒm tra náº¿u Ä‘Ã£ Ä‘áº¡t Ä‘Ã­ch
        if current_state == goal_state:
            return path

        zero_idx = current_state.index(0)
        moves = [-3, 3, -1, 1]  # LÃªn, Xuá»‘ng, TrÃ¡i, Pháº£i

        for move in moves:
            new_idx = zero_idx + move

            # Kiá»ƒm tra nÆ°á»›c Ä‘i há»£p lá»‡
            if 0 <= new_idx < 9 and (
                (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or
                (move in [-3, 3])
            ):
                # KhÃ´ng cho swap lÃ m áº£nh hÆ°á»Ÿng Ä‘áº¿n Ã´ 0,1,2
                if new_idx in observed_indices:
                    continue  # Bá» qua nÆ°á»›c Ä‘i náº¿u lÃ m thay Ä‘á»•i Ã´ 1,2,3 cá»‘ Ä‘á»‹nh

                # ThÃªm tráº¡ng thÃ¡i má»›i vÃ o hÃ ng Ä‘á»£i
                new_state = current_state[:]
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                if tuple(new_state) not in visited:
                    visited.add(tuple(new_state))
                    queue.append((new_state, path + [(zero_idx, new_idx)]))

    return None

# Danh sÃ¡ch cÃ¡c bÆ°á»›c di chuyá»ƒn há»£p lá»‡
def get_next_states(state):
    moves = [-3, 3, -1, 1]  # CÃ¡c di chuyá»ƒn: lÃªn (-3), xuá»‘ng (3), trÃ¡i (-1), pháº£i (1)
    next_states = []
    zero_idx = state.index(0)  # TÃ¬m vá»‹ trÃ­ cá»§a Ã´ 0

    for move in moves:
        new_idx = zero_idx + move

        # Kiá»ƒm tra xem Ã´ má»›i cÃ³ há»£p lá»‡ khÃ´ng (khÃ´ng ra ngoÃ i ma tráº­n 3x3)
        if 0 <= new_idx < 9 and (
            (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or  # KhÃ´ng di chuyá»ƒn sang Ã´ ngoÃ i cÃ¹ng hÃ ng
            (move in [-3, 3])  # Di chuyá»ƒn lÃªn xuá»‘ng
        ):
            new_state = state[:]
            new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]  # HoÃ¡n Ä‘á»•i Ã´ 0 vá»›i Ã´ káº¿ tiáº¿p
            next_states.append((new_state, (zero_idx, new_idx)))

    return next_states
def find_solution_path(start_state, goal_state=[1, 2, 3, 4, 5, 6, 7, 8, 0]):
    """
    TÃ¬m Ä‘Æ°á»ng Ä‘i tá»« tráº¡ng thÃ¡i báº¯t Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i Ä‘Ã­ch báº±ng thuáº­t toÃ¡n A*
    Tráº£ vá» danh sÃ¡ch cÃ¡c tuple (zero_idx, swap_idx) biá»ƒu diá»…n cÃ¡c bÆ°á»›c di chuyá»ƒn
    """
    from heapq import heappush, heappop
    from DoAn8Puzzle.utils import manhattan_distance, is_solvable
    
    # Kiá»ƒm tra xem cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c khÃ´ng
    from DoAn8Puzzle.utils import is_solvable
    if not is_solvable(start_state) and is_solvable(goal_state):
        print("Tráº¡ng thÃ¡i khÃ´ng thá»ƒ giáº£i Ä‘Æ°á»£c")
        return []

    visited = set()
    queue = [(manhattan_distance(start_state), 0, start_state, [])]  # (f, g, state, path)
    
    while queue:
        _, g, state, path = heappop(queue)
        
        if state == goal_state:
            return path
        
        state_tuple = tuple(state)
        if state_tuple in visited:
            continue
            
        visited.add(state_tuple)
        zero_idx = state.index(0)
        
        # CÃ¡c nÆ°á»›c Ä‘i cÃ³ thá»ƒ: lÃªn, xuá»‘ng, trÃ¡i, pháº£i
        moves = [
            (-3, "up"),    # LÃªn
            (3, "down"),   # Xuá»‘ng
            (-1, "left"),  # TrÃ¡i
            (1, "right")   # Pháº£i
        ]
        
        for move, _ in moves:
            new_idx = zero_idx + move
            
            # Kiá»ƒm tra nÆ°á»›c Ä‘i há»£p lá»‡
            if (
                0 <= new_idx < 9 and  # Trong pháº¡m vi báº£ng 3x3
                (move != -1 or zero_idx % 3 != 0) and  # KhÃ´ng vÆ°á»£t trÃ¡i khi á»Ÿ cá»™t trÃ¡i nháº¥t
                (move != 1 or zero_idx % 3 != 2) and   # KhÃ´ng vÆ°á»£t pháº£i khi á»Ÿ cá»™t pháº£i nháº¥t
                (move != -3 or zero_idx >= 3) and      # KhÃ´ng vÆ°á»£t lÃªn khi á»Ÿ hÃ ng trÃªn cÃ¹ng
                (move != 3 or zero_idx < 6)            # KhÃ´ng vÆ°á»£t xuá»‘ng khi á»Ÿ hÃ ng dÆ°á»›i cÃ¹ng
            ):
                new_state = state.copy()
                # HoÃ¡n Ä‘á»•i vá»‹ trÃ­
                new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
                
                # Chá»‰ thÃªm vÃ o hÃ ng Ä‘á»£i náº¿u tráº¡ng thÃ¡i má»›i chÆ°a Ä‘Æ°á»£c duyá»‡t
                if tuple(new_state) not in visited:
                    # TÃ­nh toÃ¡n f = g + h vá»›i g lÃ  sá»‘ bÆ°á»›c Ä‘i vÃ  h lÃ  khoáº£ng cÃ¡ch Manhattan
                    new_g = g + 1
                    new_f = new_g + manhattan_distance(new_state)
                    heappush(queue, (new_f, new_g, new_state, path + [(zero_idx, new_idx)]))
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y giáº£i phÃ¡p
    return []

#n
def genetic_algorithm_solve(start_state, population_size=200, max_generations=500, mutation_rate=0.1, timeout=50):
    goal_state = list(range(1, 9)) + [0]
    if start_state == goal_state:
        return []

    if not is_solvable(start_state):
        print("Tráº¡ng thÃ¡i khÃ´ng thá»ƒ giáº£i Ä‘Æ°á»£c!")
        return None

    # CÃ¡c bÆ°á»›c di chuyá»ƒn: lÃªn, xuá»‘ng, trÃ¡i, pháº£i
    move_map = [-3, 3, -1, 1]

    # HÃ m táº¡o cÃ¡ thá»ƒ má»›i báº±ng cÃ¡ch sinh ngáº«u nhiÃªn lengthh bÆ°á»›c Ä‘i
    def create_individual(length=100):
        return [random.randint(0, 3) for _ in range(length)]

    # Ãp dá»¥ng chuá»—i bÆ°á»›c Ä‘i lÃªn tráº¡ng thÃ¡i
    def apply_moves(state, moves):
        s = state[:]
        valid_path = [] # LÆ°u láº¡i cÃ¡c bÆ°á»›c Ä‘i há»£p lá»‡
        last_move = None # TrÃ¡nh láº·p láº¡i hÆ°á»›ng ngÆ°á»£c

        for move in moves:
            zero = s.index(0)
            new_zero = zero + move_map[move]

            # KhÃ´ng Ä‘i ngÆ°á»£c láº¡i bÆ°á»›c trÆ°á»›c
            if last_move is not None and abs(move_map[move]) == abs(move_map[last_move]):
                continue

            if 0 <= new_zero < 9:
                if move in [2, 3] and zero // 3 != new_zero // 3:
                    continue  # TrÃ¡nh Ä‘i trÃ¡i/pháº£i mÃ  vÆ°á»£t ra khá»i hÃ ng
                s[zero], s[new_zero] = s[new_zero], s[zero]
                valid_path.append((zero, new_zero))
                last_move = move
        return s, valid_path
    # HÃ m tÃ­nh Ä‘iá»ƒm fitness cho cÃ¡ thá»ƒ dá»±a vÃ o hÃ m Manhattan
    # CÃ ng gáº§n goal(khoáº£ng cÃ¡ch Manhattan cÃ ng nhá») thÃ¬ Ä‘iá»ƒm cÃ ng cao
    # CÃ ng ngáº¯n thÃ¬ tá»‘t hÆ¡n -> trá»« Ä‘iá»ƒm 0.1 cho má»—i bÆ°á»›c Ä‘i
    def fitness(state, path):
        dist = manhattan_distance(state) 
        return 1000 - dist - 0.1 * len(path) # Trá»« Ä‘iá»ƒm cho má»—i bÆ°á»›c Ä‘i
    
    # HÃ m lai ghÃ©p 2 cÃ¡ thá»ƒ Ä‘á»ƒ táº¡o ra cÃ¡ thá»ƒ má»›i
    def crossover(p1, p2):
        point = random.randint(1, min(len(p1), len(p2)) - 1) # Chá»n ngáº«u nhiÃªn Ä‘iá»ƒm cáº¯t cá»§a p1 Ä‘á»ƒ trá»™n vá»›i p2
        return p1[:point] + p2[point:]

    # HÃ m Ä‘á»™t biáº¿n cÃ¡ thá»ƒ vá»›i xÃ¡c suáº¥t rate - tá»©c thay Ä‘á»•i ngáº«u nhiÃªn má»™t bÆ°á»›c Ä‘i trong cÃ¡ thá»ƒ
    def mutate(ind, rate):
        return [random.randint(0, 3) if random.random() < rate else m for m in ind]

    # Khá»Ÿi táº¡o quáº§n thá»ƒ ban Ä‘áº§u
    population = [create_individual() for _ in range(population_size)]
    # Biáº¿n theo dÃµi cÃ¡ thá»ƒ tá»‘t nháº¥t
    best_score = float('-inf')
    best_path = []

    start = time.time()
    for gen in range(max_generations):
        if time.time() - start > timeout:
            print("Háº¿t thá»i gian!")
            break

        scored = []
        # Cháº¡y má»—i bÆ°á»›c lÃªn start state, tÃ­nh Ä‘iá»ƒm vÃ  lÆ°u láº¡i -> Ä‘Ã¡nh giÃ¡ táº¥t cáº£ cÃ¡ thá»ƒ
        for ind in population:
            final_state, path = apply_moves(start_state, ind)
            score = fitness(final_state, path)
            scored.append((score, ind, path, final_state))
            if final_state == goal_state:
                print(f"TÃ¬m tháº¥y lá»i giáº£i táº¡i tháº¿ há»‡ {gen}")
                return path

        scored.sort(reverse=True)
        population = [ind for _, ind, _, _ in scored[:population_size // 4]]  #Giá»¯ láº¡i top 25% cÃ¡ thá»ƒ tá»‘t nháº¥t

        # Lai ghÃ©p vÃ  Ä‘á»™t biáº¿n Ä‘á»ƒ táº¡o child
        while len(population) < population_size:
            p1 = random.choice(scored)[1]
            p2 = random.choice(scored)[1]
            child = mutate(crossover(p1, p2), mutation_rate)
            population.append(child)

        # Cáº­p nháº­t cÃ¡ thá»ƒ tá»‘t nháº¥t
        if scored[0][0] > best_score:
            best_score = scored[0][0]
            best_path = scored[0][2]

        if gen % 10 == 0:
            print(f"ğŸ” Tháº¿ há»‡ {gen}, Ä‘iá»ƒm tá»‘t nháº¥t: {int(best_score)}")

    print("KhÃ´ng tÃ¬m Ä‘Æ°á»£c tráº¡ng thÃ¡i goal. Tráº£ vá» Ä‘Æ°á»ng Ä‘i tá»‘t nháº¥t.")
    return best_path if best_path else None

# HÃ m giáº£i thuáº­t Q-Learning: giáº£i 8-puzzle sá»­ dá»¥ng thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng
def q_learning_solve(start_state, episodes=5000, alpha=0.1, gamma=0.9, epsilon=0.2):
    import random
    from collections import defaultdict

    goal_state = tuple([1, 2, 3, 4, 5, 6, 7, 8, 0])
    # BÆ°á»›c 1: Khá»Ÿi táº¡o Q-table vÃ  Ä‘iá»n cÃ¡c giÃ¡ trá»‹ ban Ä‘áº§u
    Q = defaultdict(lambda: [0, 0, 0, 0])  # Q(s,a) vá»›i 4 hÃ nh Ä‘á»™ng: up, down, left, right
    actions = [(-3, 0), (3, 1), (-1, 2), (1, 3)]  # (di chuyá»ƒn, chá»‰ sá»‘ hÃ nh Ä‘á»™ng)

    # HÃ m xÃ¡c Ä‘á»‹nh hÃ nh Ä‘á»™ng há»£p lá»‡ tá»« tráº¡ng thÃ¡i hiá»‡n táº¡i
    def get_valid_actions(state):
        zero = state.index(0)
        valid = []
        for move, idx in actions:
            new_zero = zero + move
            if 0 <= new_zero < 9:
                if abs(zero % 3 - new_zero % 3) + abs(zero // 3 - new_zero // 3) == 1:
                    valid.append((move, idx))
        return valid

    # HÃ m hoÃ¡n Ä‘á»•i vá»‹ trÃ­ cá»§a Ã´ trá»‘ng (0) vá»›i Ã´ bÃªn cáº¡nh -> tráº£ vá» tráº¡ng thÃ¡i má»›i
    def step(state, move):
        zero = state.index(0)
        new_zero = zero + move
        new_state = list(state)
        new_state[zero], new_state[new_zero] = new_state[new_zero], new_state[zero]
        return tuple(new_state)

    # BÆ°á»›c 2: VÃ²ng láº·p há»c theo sá»‘ lÆ°á»£ng episode
    for ep in range(episodes):
        state = tuple(start_state)

        for _ in range(100):  # Tá»‘i Ä‘a 50 bÆ°á»›c má»—i episode
            # BÆ°á»›c 3: Chá»n tÃ¡c nhÃ¢n thá»±c hiá»‡n hÃ nh Ä‘á»™ng lÃªn tráº¡ng thÃ¡i s(k)
            valid = get_valid_actions(state)
            if not valid:
                break

            if random.random() < epsilon:
                move, a = random.choice(valid)
            else:
                best = max(valid, key=lambda m: Q[state][m[1]]) # Chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t dá»±a trÃªn Q-value
                move, a = best

            # BÆ°á»›c 5: chuyá»ƒn sang tráº¡ng thÃ¡i má»›i
            next_state = step(state, move)

            # BÆ°á»›c 4: tÃ­nh pháº§n thÆ°á»Ÿng
            reward = 100 if next_state == goal_state else -1

            # BÆ°á»›c 6: cáº­p nháº­t Q-value theo cÃ´ng thá»©c
            max_q_next = max(Q[next_state])
            Q[state][a] += alpha * (reward + gamma * max_q_next - Q[state][a])

            state = next_state

            # BÆ°á»›c 7: káº¿t thÃºc náº¿u Ä‘áº¿n goal
            if state == goal_state:
                break

        # BÆ°á»›c 8: reset mÃ´i trÆ°á»ng lÃ  implicit khi báº¯t Ä‘áº§u vÃ²ng láº·p má»›i

    # Sau khi há»c xong, giáº£i báº±ng cÃ¡ch dÃ¹ng Q-value
    path = []
    state = tuple(start_state)
    visited = set()
    for _ in range(50):
        visited.add(state)
        valid = get_valid_actions(state)
        if not valid:
            break

        best = max(valid, key=lambda m: Q[state][m[1]])
        move, a = best
        zero = state.index(0)
        new_zero = zero + move
        path.append((zero, new_zero))
        state = step(state, move)
        if state in visited:
            break
        if state == goal_state:
            return path

    return path if state == goal_state else None



# # HÃ m giáº£i thuáº­t TD Learning: giáº£i 8-puzzle sá»­ dá»¥ng thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng Temporal Difference
def td_learning_solve(start_state, episodes=5000, alpha=0.2, gamma=0.9, epsilon=0.3):
    import random
    from collections import defaultdict

    goal_state = tuple([1, 2, 3, 4, 5, 6, 7, 8, 0])
    
    # Khá»Ÿi táº¡o báº£ng giÃ¡ trá»‹ tráº¡ng thÃ¡i V(s)
    V = defaultdict(float)
    # Tráº¡ng thÃ¡i Ä‘Ã­ch cÃ³ giÃ¡ trá»‹ cao nháº¥t
    V[goal_state] = 100.0
    
    # HÃ m xÃ¡c Ä‘á»‹nh hÃ nh Ä‘á»™ng há»£p lá»‡ tá»« tráº¡ng thÃ¡i hiá»‡n táº¡i
    def get_valid_actions(state):
        zero = state.index(0)
        valid = []
        # CÃ¡c hÆ°á»›ng di chuyá»ƒn: lÃªn (-3), xuá»‘ng (3), trÃ¡i (-1), pháº£i (1)
        actions = [(-3, "up"), (3, "down"), (-1, "left"), (1, "right")]
        
        for move, direction in actions:
            new_idx = zero + move
            if 0 <= new_idx < 9:
                # Kiá»ƒm tra nÆ°á»›c Ä‘i há»£p lá»‡
                if (move == -1 and zero % 3 == 0) or (move == 1 and zero % 3 == 2):
                    continue  # KhÃ´ng Ä‘i ra ngoÃ i hÃ ng
                if (move == -3 and zero < 3) or (move == 3 and zero > 5):
                    continue  # KhÃ´ng Ä‘i ra ngoÃ i cá»™t
                valid.append((zero, new_idx, direction))
                
        return valid

    # HÃ m Ã¡p dá»¥ng nÆ°á»›c Ä‘i vÃ  táº¡o tráº¡ng thÃ¡i má»›i
    def apply_move(state, move):
        zero_idx, new_idx, _ = move
        new_state = list(state)
        new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
        return tuple(new_state)

    # HÃ m chá»n nÆ°á»›c Ä‘i dá»±a trÃªn epsilon-greedy
    def choose_action(state, epsilon):
        valid_moves = get_valid_actions(state)
        
        # KhÃ´ng cÃ³ nÆ°á»›c Ä‘i há»£p lá»‡
        if not valid_moves:
            return None
        
        # Epsilon-greedy: khÃ¡m phÃ¡ vs khai thÃ¡c
        if random.random() < epsilon:
            # KhÃ¡m phÃ¡: chá»n ngáº«u nhiÃªn má»™t nÆ°á»›c Ä‘i
            return random.choice(valid_moves)
        else:
            # Khai thÃ¡c: chá»n nÆ°á»›c Ä‘i cÃ³ giÃ¡ trá»‹ cao nháº¥t
            best_value = -float('inf')
            best_moves = []
            
            for move in valid_moves:
                next_state = apply_move(state, move)
                if V[next_state] > best_value:
                    best_value = V[next_state]
                    best_moves = [move]
                elif V[next_state] == best_value:
                    best_moves.append(move)
            
            # Chá»n ngáº«u nhiÃªn trong sá»‘ cÃ¡c nÆ°á»›c Ä‘i tá»‘t nháº¥t
            return random.choice(best_moves)

    print(f"TD Learning: training with {episodes} episodes...")
    
    # Huáº¥n luyá»‡n qua nhiá»u táº­p dá»¯ liá»‡u
    for episode in range(episodes):
        # Giáº£m dáº§n epsilon Ä‘á»ƒ Æ°u tiÃªn khai thÃ¡c hÆ¡n khÃ¡m phÃ¡
        current_epsilon = max(0.05, epsilon * (1 - episode / episodes))
        
        state = tuple(start_state)
        step_count = 0
        max_steps = 100  # Giá»›i háº¡n sá»‘ bÆ°á»›c má»—i episode
        
        while state != goal_state and step_count < max_steps:
            # Chá»n nÆ°á»›c Ä‘i 
            move = choose_action(state, current_epsilon)
            if not move:
                break
                
            # Ãp dá»¥ng nÆ°á»›c Ä‘i Ä‘á»ƒ cÃ³ tráº¡ng thÃ¡i má»›i
            next_state = apply_move(state, move)
            
            # TÃ­nh toÃ¡n pháº§n thÆ°á»Ÿng: -1 cho má»—i bÆ°á»›c, 100 náº¿u Ä‘áº¡t Ä‘Ã­ch
            reward = 100 if next_state == goal_state else -1
            
            # Cáº­p nháº­t V(s) theo cÃ´ng thá»©c TD(0): V(s) = V(s) + alpha * [R + gamma * V(s') - V(s)]
            td_target = reward + gamma * V[next_state]
            td_error = td_target - V[state]
            V[state] += alpha * td_error
            
            # Chuyá»ƒn sang tráº¡ng thÃ¡i káº¿ tiáº¿p
            state = next_state
            step_count += 1
        
        # In thÃ´ng tin tiáº¿n Ä‘á»™
        if (episode + 1) % 500 == 0:
            print(f"Episode {episode + 1}/{episodes} completed")

    # Sau khi huáº¥n luyá»‡n, sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ Ä‘Ã£ há»c Ä‘á»ƒ tÃ¬m giáº£i phÃ¡p
    print("Training complete. Finding solution path...")
    state = tuple(start_state)
    path = []
    visited = set([state])
    max_solution_steps = 50
    
    # Giáº£m epsilon xuá»‘ng tháº¥p Ä‘á»ƒ Æ°u tiÃªn khai thÃ¡c hÆ¡n khÃ¡m phÃ¡
    solution_epsilon = 0.05
    
    for _ in range(max_solution_steps):
        if state == goal_state:
            print(f"Goal reached in {len(path)} steps!")
            return path
            
        # Chá»n nÆ°á»›c Ä‘i tá»‘t nháº¥t tá»« tráº¡ng thÃ¡i hiá»‡n táº¡i
        move = choose_action(state, solution_epsilon)
        if not move:
            print("No valid moves available")
            break
            
        # LÆ°u vÃ o Ä‘Æ°á»ng Ä‘i vÃ  cáº­p nháº­t tráº¡ng thÃ¡i
        zero_idx, new_idx, _ = move
        path.append((zero_idx, new_idx))
        
        # Cáº­p nháº­t tráº¡ng thÃ¡i
        state = apply_move(state, move)
        
        # Kiá»ƒm tra láº·p vÃ²ng
        if state in visited:
            print("Loop detected, breaking")
            break
            
        visited.add(state)
    
    # Tráº£ vá» Ä‘Æ°á»ng Ä‘i náº¿u cÃ³ hoáº·c None náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c
    return path if path else None
def backtracking_search_solve( start_state, max_depth=30):
        goal = list(range(1, 9)) + [0]

        def is_complete(state):
            return state == goal

        def select_unassigned_variable(state):
            return [i for i in range(9) if state[i] != goal[i]]

        def order_domain_values(index):
            domain = list(range(9))
            random.shuffle(domain)
            return [i for i in domain if i != index]

        def recursive_backtracking(state, path, visited, depth):
            if depth > max_depth:
                return None
            if is_complete(state):
                return path

            key = tuple(state)
            if key in visited:
                return None
            visited.add(key)

            unassigned = select_unassigned_variable(state)
            if not unassigned:
                return None

            var = unassigned[0]
            for value in order_domain_values(var):
                new_state = state[:]
                new_state[var], new_state[value] = new_state[value], new_state[var]
                if new_state != state:
                    result = recursive_backtracking(new_state, path + [(var, value)], visited, depth + 1)
                    if result:
                        return result
            return None

        return recursive_backtracking(start_state[:], [], set(), 0)
def constraint_checking_solve( start_state):
        from collections import deque
        goal = list(range(1, 9)) + [0]
        visited = set()
        queue = deque([(start_state, [])])

        while queue:
            state, path = queue.popleft()
            if state == goal:
                return path

            zero_idx = state.index(0)
            moves = [-3, 3, -1, 1]

            for move in moves:
                new_idx = zero_idx + move
                if 0 <= new_idx < 9 and (
                    (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or
                    (move in [-3, 3])
                ):
                    new_state = state[:]
                    new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]

                    if tuple(new_state) not in visited:
                        visited.add(tuple(new_state))
                        queue.append((new_state, path + [(zero_idx, new_idx)]))
        return None
def ac3_solve( start_state):
        from collections import deque
        goal = list(range(1, 9)) + [0]
        visited = set()
        queue = deque([(start_state, [])])

        while queue:
            state, path = queue.popleft()
            if state == goal:
                return path

            zero_idx = state.index(0)
            moves = [-3, 3, -1, 1]
            for move in moves:
                new_idx = zero_idx + move
                if 0 <= new_idx < 9 and (
                    (move in [-1, 1] and zero_idx // 3 == new_idx // 3) or
                    (move in [-3, 3])
                ):
                    new_state = state[:]
                    new_state[zero_idx], new_state[new_idx] = new_state[new_idx], new_state[zero_idx]
                    if tuple(new_state) not in visited:
                        visited.add(tuple(new_state))
                        queue.append((new_state, path + [(zero_idx, new_idx)]))
        return None   